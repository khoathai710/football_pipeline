# The data pipeline system for the Premier League 2025-2026

## 1. Introduction
This is a batch-processing data pipeline designed to collect weekly data for the 2025/2026 English Premier League season.
The system follows a typical ETL (Extract â€“ Transform â€“ Load) workflow.

What makes this system particularly unique is that its final stage is a Chatbot ðŸ¤– is **ScoutAI**. \
The Chatbot retrieves data from the data warehouse and interacts with users to answer their questions.


## 2. Design
### 2.1 Data pipeline
<img width="959" height="528" alt="image" src="https://github.com/user-attachments/assets/6148f3a7-114a-40d2-8f3d-90d5e6fea365" /> \
- We use Docker to containerize the application and Dagster to orchestrate assets.
- Data sources:  
  - Web: [premierleague.com](https://www.premierleague.com) for matches, match details, players, clubs, â€¦  
  - MySQL: for additional data about stadiums   
- All data from the first step is stored in MinIO as the data lake.  
- The loaded data from MinIO is then cleaned and transformed using Spark, producing silver and gold data.  
- The data is partitioned weekly (e.g., week_{}.parquet), since new matches and updates occur on a weekly basis.  
- The transformed data is loaded into PostgreSQL as the data warehouse and further modeled into data marts using dbt.  
- Finally, a Chatbot is created to query the data marts, allowing users to ask questions such as "Who is leading in goals?"
### 2.2 Project Structure
<img width="440" height="564" alt="image" src="https://github.com/user-attachments/assets/3f598ab8-2d2d-4c3e-b4a6-291e9b6b4566" />

- **chatbot/**: Source code of the ScoutAI Chatbot.  
- **Dagster/**: Configurations and asset definitions for Dagster pipelines.  
- **dagster_home/**: Runtime files generated by Dagster (metadata, runs, logs).    
- **etl_pipeline/**: Core ETL logic (Extract, Transform, Load).  
- **football/**: dbt project for building data marts.    
- **Spark/**: Spark jobs and configurations for transformations.  

- **.env**: Environment variables (DB, MinIO, API keys, ...).  
- **docker-compose.yaml**: Docker Compose setup for running the full system.  
- **Makefile**: Utility commands for building and running the project.  
- **requirements.txt**: Python dependencies list.  

### 2.3 Datalake structure
<img width="411" height="655" alt="image" src="https://github.com/user-attachments/assets/382358ea-78df-4ad6-a07a-1476e2b8b67f" />

- The data lake is organized into three layers: **bronze**, **silver**, and **gold**.  
- All datasets are stored in **Parquet** format for efficient storage and querying.  
- Data is stored either as **full datasets** or in **weekly partitions** depending on update frequency.  

### 2.3 Data linage
#### 2.3.1 Global linage
<img width="919" height="355" alt="image" src="https://github.com/user-attachments/assets/e68dc984-c362-444d-b388-6475589c56a2" /> \
#### 2.3.2 Bronze layer
<img width="1686" height="465" alt="image" src="https://github.com/user-attachments/assets/ea74f286-faee-4b45-ae10-af2160edf642" /> 

- **bronze_matches_dataset**: contains all information about matches such as goals, assists, cards, referees, substitutions, â€¦ and is materialized weekly  
- **bronze_football_stadiums_dataset**: contains information about the stadiums of each team and is materialized once  
- **bronze_player_info_dataset**: contains information about players (e.g., name, age, nationality, position, â€¦) and is materialized once  
- **bronze_teams_dataset**: contains information about teams (e.g., club name, manager, squad, â€¦) and is materialized once
#### 2.3.3 Silver layer
<img width="1776" height="420" alt="image" src="https://github.com/user-attachments/assets/51b9be32-b7cd-44b2-ad1a-d7d63c4342e8" />

- silver_goals_assists: extract and normalize goals & assists per match (weekly).  
- silver_cards: process yellow/red cards with time and player info (weekly).  
- silver_appearance: record player appearances (starting/subs) by match (weekly).  
- silver_player_info: clean player full name into first/last name (weekly).  
- silver_match_score: integrate match results with teams and man of the match (weekly).  
- silver_team_info: combine team info with stadium details (one-time).  

#### 2.3.4 Gold layer
<img width="1085" height="347" alt="image" src="https://github.com/user-attachments/assets/6eddde18-6b56-4d10-886c-8bf60deabc56" />

- gold_goals_assists: integrate goals & assists with player details (weekly, Spark)  
- gold_cards: integrate card events with player details (weekly, Spark)  
- gold_appearance: clean and standardize player appearances (weekly, Pandas)  
- gold_player_info: standardized player information (one-time, Pandas)  
- gold_match_score: standardized match results with teams & scores (weekly, Pandas)  
- gold_team_info: standardized team information with stadium details (one-time, Pandas)

### 2.4 Containerize
<p float="left">
  <img width="45%" height="666" alt="image" src="https://github.com/user-attachments/assets/de24e2f2-6329-4740-b068-a0019db9b20c" />
  <img width="45%" height="540" alt="image" src="https://github.com/user-attachments/assets/28d944e4-efda-4ec8-ae0b-9056161625a1" />
</p>


**etl_pipeline**
- ports: none exposed  
- explanation: Contains the main ETL code, connected with Dagster to run pipelines.  

---
**de_mysql (MySQL)**
- ports: `3306:3306`  
- explanation: MySQL database for storing raw data.  
  Also mounts `./minio:/data` to communicate with MinIO.  

---
**de_psql (PostgreSQL)**
- ports: `5430:5432`  
- explanation: PostgreSQL database, usually used as a data warehouse or data mart for analytics.  

---
**de_dagster**
- ports: none exposed  
- explanation: Container building the Dagster image, where pipelines are executed.  

---
**de_dagster_dagit (Dagit UI)**  
- ports: `3001:3001`  
- explanation: Dagster web interface for monitoring pipelines, triggering jobs, and checking logs.  

---
**de_dagster_daemon (Dagster Daemon)**  
- ports: none exposed  
- explanation: Background process that manages Dagster jobs, schedules, and sensors.  

---
**minio (Object Storage, S3-like)**  
- ports: `9000:9000` (API), `9001:9001` (Web Console)  
- explanation: Object storage service (similar to Amazon S3). Used for storing raw, intermediate, or warehouse data.  

---
**mc (MinIO Client)**  
- ports: none exposed  
- explanation: CLI client for MinIO, used to create buckets (e.g., `warehouse`) and configure policies.  

---
**spark-master**  
- ports: `8080:8080` (Master UI), `4040:4040` (Application UI)  
- explanation: The master node of the Spark cluster, managing workers and job execution.  

---
**spark-worker**  
- ports: none exposed  
- explanation: Worker node in the Spark cluster, executes tasks assigned by the Spark Master.
## 3. Data Source
To retrieve information about a specific match, the pipeline follows these steps:

1. **Access the website** [premierleague.com](https://www.premierleague.com)  
   Welcome page:  
   <img width="1883" height="822" alt="image" src="https://github.com/user-attachments/assets/9cde0dbd-47ae-4fac-b858-df0ff54594b4" />

2. **Navigate to the match page**  
   <img width="1885" height="828" alt="Screenshot 2025-10-03 121055" src="https://github.com/user-attachments/assets/98277ca0-4f06-4c57-a74e-9717f92493cd" />

3. **Collect detailed information from multiple tabs** (e.g., *Recap*, *Lineups*, *Stats*)  
   <img width="1891" height="829" alt="Screenshot 2025-10-03 121542" src="https://github.com/user-attachments/assets/6f2ce387-1c64-4060-af57-c7328cff7f06" />
4. All match data will be crawled using **Selenium**, extracted into **JSON format**, and then stored in **MinIO** for the next ETL steps.  
   For example, the following HTML snippet contains information about goals and assists:  
   <img width="434" height="388" alt="Screenshot 2025-10-03 122136" src="https://github.com/user-attachments/assets/d360e3f2-e4b3-499b-a54a-9c3d89c141fb" />

  
## 4. Transformation with dbt
We use **SQL-based transformations** in the `models/` folder inside the `football` dbt project.  
To build the models, simply run:

```bash
dbt run
```
<img width="1046" height="545" alt="image" src="https://github.com/user-attachments/assets/474c176a-d5a8-4b5a-8462-8029e0e2f65b" />


## 5. Chatbot
The chatbot is designed to:  
- Answer questions about **Premier League teams, players, and matches**.  
- Provide quick access to **links, scores, and basic statistics**.  
- Support interaction with the **underlying database and warehouse** through natural language.  
- Help users explore insights from the **ETL & dbt pipeline** in a simple way.

<p float="left">
  <img src="https://github.com/user-attachments/assets/d335e42c-c943-4c1d-b833-453ba8e1cf5f" width="45%" />
  <img src="https://github.com/user-attachments/assets/2e93661b-9154-4794-b933-dfa8fdcd0f4b" width="45%" />
</p>

## 6. Acknowledgments

Thank you for reading this project!  
We truly appreciate your interest and support.
